{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKT0nrclcbfA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_params_deep(layer_dims):\n",
        "  u = len(layer_dims)\n",
        "  params = {}\n",
        "  for i in range(1,u):\n",
        "    W = np.random.rand(i,i-1)\n",
        "    b = np.random.rand(i,1)\n",
        "    params[f\"W{i}\"] = W\n",
        "    params[f\"b{i}\"] = b\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "UkytumsFfx3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "  A = 1 / (1+ np.exp(-Z))\n",
        "  cache = (Z)\n",
        "  return A, cache\n"
      ],
      "metadata": {
        "id": "2AO7a6eGpsNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "  A = max(0,Z)\n",
        "  cache = Z\n",
        "\n",
        "  return A,cache"
      ],
      "metadata": {
        "id": "tXEwph9Ur_PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A,W,b):\n",
        "  Z =  np.dot(W,A) + b #A : activations from the previous layer\n",
        "  cache = (A,W,b)\n",
        "  return Z,cache"
      ],
      "metadata": {
        "id": "mJLnP4WHga8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "\n",
        "  if activation == \"sigmoid\":\n",
        "    Z, linear_cache = linear_forward(A_prev,W,b)\n",
        "    A, activation_cache = sigmoid(Z)\n",
        "\n",
        "  else :\n",
        "    Z, linear_cache = linear_forward(A_prev,W,b)\n",
        "    A, activation_cache = relu(Z)\n",
        "\n",
        "  cache = (linear_cache, activation_cache)\n",
        "\n",
        "  return A , cache"
      ],
      "metadata": {
        "id": "idrm35INofSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_forward(X,parameters):\n",
        "  A = X\n",
        "  caches = []\n",
        "  l  = len(parameters) // 2\n",
        "  for i in range(l-1):\n",
        "    A, cache = linear_activation_forward(A,parameters[f\"W{i}\"],parameters[f\"b{i}\"],\"relu\")\n",
        "    caches.append(cache)\n",
        "\n",
        "  Al,cache = linear_activation_forward(A,parameters[f\"W{i}\"],parameters[f\"b{i}\"],\"sigmoid\")\n",
        "  caches.append(cache)\n",
        "\n",
        "  return Al,caches"
      ],
      "metadata": {
        "id": "fUy3pCywsbyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(y_pred,y):\n",
        "  p1 = np.multiply(y,np.log(y_pred).T)\n",
        "  p2 = np.multiply((1-y),np.log((1-y_pred)).T)\n",
        "  m = y.shape[0]\n",
        "  cost = (-1/m) * (p1+p2)\n",
        "  cost = np.squeeze(cost)\n",
        "  return cost"
      ],
      "metadata": {
        "id": "Zhk8ONM3yuQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}